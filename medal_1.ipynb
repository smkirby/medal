{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smkirby/medal/blob/main/medal_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V238Ecnyxl5Z"
      },
      "source": [
        "# Medal summer school, Lab 1, Compositionality from iterated learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5LYLbdyxl5b"
      },
      "source": [
        "In this lab, we'll be building a replication of the simulation in [Kirby et al (2015)](https://www.sciencedirect.com/science/article/pii/S0010027715000815?via%3Dihub) which looks at how compositional structure can evolve if language is both transmitted to new learners each generation *and* used for communication. This is a pretty close replication of the original paper, but with a noteable simplification, namely that learners assume that they are learning a single language (even if that language might actually have been generated by multiple speakers who might each have been speaking a different language). This simplification doesn't seem to alter the results much and means we don't need a supercomputer to run the simulations, which is a bonus!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3tF6vP4xl5c"
      },
      "source": [
        "## Representing meanings, signals, and grammars\n",
        "\n",
        "In order to look at compositional structure we have to have some representation of languages as a mapping between meanings and signals. In a compositional language, the signal associated with a meaning depends in a predictable way on the components of that meaning, with each part of the signal conveying part of the meaning.\n",
        "\n",
        "In order to keep thing manageable we're using a very simple meaning space (probably the simplest possible!): each meaning consists of two features, each of which can take two possible values, which means there are 4 possible meanings our language has to encode. If it helps, you can think of the first meaning feature as corresponding to shape, and the second to colour. Then `0` might be *square*, `1` might be *circle*, `2` could be *red*, and `3` could be *blue*. In this way `02` represents the meaning *red square*.\n",
        "\n",
        "In the same way, our signal space consists of just four possible sentences (two-letter strings made up of *a*s and *b*s, i.e. `aa`, `ab`, `ba`, `bb`). Again, you can imagine that `a` and `b` correspond to different words and each signal consists of a two-word sentence, or you can imagine that they are morphemes and each signal consists of a multi-morphemic word.\n",
        "\n",
        "In this cell, we make two lists. One contains the meanings, and the other contains the signals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw6MOy4-xl5c"
      },
      "outputs": [],
      "source": [
        "meanings = ['02', '03', '12', '13']\n",
        "signals = ['aa', 'ab', 'ba', 'bb']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiW4L6KNxl5d"
      },
      "source": [
        "Now we have a representation of meanings and signals we can represent a language, which is a list of pairings of meanings and their associated signals. Each language consists of exactly 4 entries – four meaning-signal pairings, one signal for each meaning. Each item is a *pair*: the first item in the pair is the meaning, and the second is the signal. For example, here is a degenerate (completely ambiguous) language, where every meaning is expressed using the same signal:\n",
        "\n",
        "```python\n",
        "a_degenerate_language = [('02', 'aa'), ('03', 'aa'), ('12', 'aa'), ('13', 'aa')]\n",
        "```\n",
        "\n",
        "And here is a compositional language, where there is a reliable correspondence between components of the meaning and components of the signal that expresses it:\n",
        "\n",
        "```python\n",
        "a_compositional_language = [('02', 'aa'), ('03', 'ab'), ('12', 'ba'), ('13', 'bb')]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8gT7gftxl5d"
      },
      "source": [
        "Check that you understand how meanings, signals and languages are represented, and why `a_compositional_language` is compositional, then create another degenerate language and another compositional language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDnWtGoXxl5d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgMdBmZQxl5d"
      },
      "source": [
        "Now that we have defined what a language looks like, we can lay out the hypothesis space – the space of all possible languages – and the priors for those languages. The prior represents the belief a learner will have in that language before being exposed to any data at all. In other words, it represents the biases that the learner has innately - or equivalently how easy or hard it will be to learn that language. More data will be needed to learn a language that has a low prior probability.\n",
        "\n",
        "Before we go any further, how many possible languages do you think there will be, given that we have only 4 meanings to express and only 4 possible signals to express them?\n",
        "\n",
        "The process of enumerating the possible languages and calculating their prior probability is actually slightly involved: the prior for each language depends on its coding length (essentially, how simple it is). To work this out, as the paper explains, we have to write down a mini grammar for each language, calculate its coding length, and then work out the prior based on that. Rather than going through all this code here, we are simply going to provide you with lists of all the possible languages (`possible_languages`), and their (log) prior probabilities (`log_priors`), which we prepared in advance based on the method in the Kirby et al. (2015) paper: the nth item in the `log_priors` list is the prior for the nth langauge in `possible_languages`. Note that we use log probabilities here rather than probabilities because we can use addition rather than multiplication to manipulate them and this avoids us ending up with very tiny numbers!\n",
        "\n",
        "Additionally we provide a list of *types* for each language (in the same order as the `possible_languages` list). Type `0` means *degenerate*, type `1` means *holistic*, type `2` is *other* (e.g. languages that are partially degenerate), and type `3` is compositional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0sm3ucaxl5e"
      },
      "outputs": [],
      "source": [
        "possible_languages = [[('02', 'aa'), ('03', 'aa'), ('12', 'aa'), ('13', 'aa')], [('02', 'aa'), ('03', 'aa'), ('12', 'aa'), ('13', 'ab')], [('02', 'aa'), ('03', 'aa'), ('12', 'aa'), ('13', 'ba')], [('02', 'aa'), ('03', 'aa'), ('12', 'aa'), ('13', 'bb')], [('02', 'aa'), ('03', 'aa'), ('12', 'ab'), ('13', 'aa')], [('02', 'aa'), ('03', 'aa'), ('12', 'ab'), ('13', 'ab')], [('02', 'aa'), ('03', 'aa'), ('12', 'ab'), ('13', 'ba')], [('02', 'aa'), ('03', 'aa'), ('12', 'ab'), ('13', 'bb')], [('02', 'aa'), ('03', 'aa'), ('12', 'ba'), ('13', 'aa')], [('02', 'aa'), ('03', 'aa'), ('12', 'ba'), ('13', 'ab')], [('02', 'aa'), ('03', 'aa'), ('12', 'ba'), ('13', 'ba')], [('02', 'aa'), ('03', 'aa'), ('12', 'ba'), ('13', 'bb')], [('02', 'aa'), ('03', 'aa'), ('12', 'bb'), ('13', 'aa')], [('02', 'aa'), ('03', 'aa'), ('12', 'bb'), ('13', 'ab')], [('02', 'aa'), ('03', 'aa'), ('12', 'bb'), ('13', 'ba')], [('02', 'aa'), ('03', 'aa'), ('12', 'bb'), ('13', 'bb')], [('02', 'aa'), ('03', 'ab'), ('12', 'aa'), ('13', 'aa')], [('02', 'aa'), ('03', 'ab'), ('12', 'aa'), ('13', 'ab')], [('02', 'aa'), ('03', 'ab'), ('12', 'aa'), ('13', 'ba')], [('02', 'aa'), ('03', 'ab'), ('12', 'aa'), ('13', 'bb')], [('02', 'aa'), ('03', 'ab'), ('12', 'ab'), ('13', 'aa')], [('02', 'aa'), ('03', 'ab'), ('12', 'ab'), ('13', 'ab')], [('02', 'aa'), ('03', 'ab'), ('12', 'ab'), ('13', 'ba')], [('02', 'aa'), ('03', 'ab'), ('12', 'ab'), ('13', 'bb')], [('02', 'aa'), ('03', 'ab'), ('12', 'ba'), ('13', 'aa')], [('02', 'aa'), ('03', 'ab'), ('12', 'ba'), ('13', 'ab')], [('02', 'aa'), ('03', 'ab'), ('12', 'ba'), ('13', 'ba')], [('02', 'aa'), ('03', 'ab'), ('12', 'ba'), ('13', 'bb')], [('02', 'aa'), ('03', 'ab'), ('12', 'bb'), ('13', 'aa')], [('02', 'aa'), ('03', 'ab'), ('12', 'bb'), ('13', 'ab')], [('02', 'aa'), ('03', 'ab'), ('12', 'bb'), ('13', 'ba')], [('02', 'aa'), ('03', 'ab'), ('12', 'bb'), ('13', 'bb')], [('02', 'aa'), ('03', 'ba'), ('12', 'aa'), ('13', 'aa')], [('02', 'aa'), ('03', 'ba'), ('12', 'aa'), ('13', 'ab')], [('02', 'aa'), ('03', 'ba'), ('12', 'aa'), ('13', 'ba')], [('02', 'aa'), ('03', 'ba'), ('12', 'aa'), ('13', 'bb')], [('02', 'aa'), ('03', 'ba'), ('12', 'ab'), ('13', 'aa')], [('02', 'aa'), ('03', 'ba'), ('12', 'ab'), ('13', 'ab')], [('02', 'aa'), ('03', 'ba'), ('12', 'ab'), ('13', 'ba')], [('02', 'aa'), ('03', 'ba'), ('12', 'ab'), ('13', 'bb')], [('02', 'aa'), ('03', 'ba'), ('12', 'ba'), ('13', 'aa')], [('02', 'aa'), ('03', 'ba'), ('12', 'ba'), ('13', 'ab')], [('02', 'aa'), ('03', 'ba'), ('12', 'ba'), ('13', 'ba')], [('02', 'aa'), ('03', 'ba'), ('12', 'ba'), ('13', 'bb')], [('02', 'aa'), ('03', 'ba'), ('12', 'bb'), ('13', 'aa')], [('02', 'aa'), ('03', 'ba'), ('12', 'bb'), ('13', 'ab')], [('02', 'aa'), ('03', 'ba'), ('12', 'bb'), ('13', 'ba')], [('02', 'aa'), ('03', 'ba'), ('12', 'bb'), ('13', 'bb')], [('02', 'aa'), ('03', 'bb'), ('12', 'aa'), ('13', 'aa')], [('02', 'aa'), ('03', 'bb'), ('12', 'aa'), ('13', 'ab')], [('02', 'aa'), ('03', 'bb'), ('12', 'aa'), ('13', 'ba')], [('02', 'aa'), ('03', 'bb'), ('12', 'aa'), ('13', 'bb')], [('02', 'aa'), ('03', 'bb'), ('12', 'ab'), ('13', 'aa')], [('02', 'aa'), ('03', 'bb'), ('12', 'ab'), ('13', 'ab')], [('02', 'aa'), ('03', 'bb'), ('12', 'ab'), ('13', 'ba')], [('02', 'aa'), ('03', 'bb'), ('12', 'ab'), ('13', 'bb')], [('02', 'aa'), ('03', 'bb'), ('12', 'ba'), ('13', 'aa')], [('02', 'aa'), ('03', 'bb'), ('12', 'ba'), ('13', 'ab')], [('02', 'aa'), ('03', 'bb'), ('12', 'ba'), ('13', 'ba')], [('02', 'aa'), ('03', 'bb'), ('12', 'ba'), ('13', 'bb')], [('02', 'aa'), ('03', 'bb'), ('12', 'bb'), ('13', 'aa')], [('02', 'aa'), ('03', 'bb'), ('12', 'bb'), ('13', 'ab')], [('02', 'aa'), ('03', 'bb'), ('12', 'bb'), ('13', 'ba')], [('02', 'aa'), ('03', 'bb'), ('12', 'bb'), ('13', 'bb')], [('02', 'ab'), ('03', 'aa'), ('12', 'aa'), ('13', 'aa')], [('02', 'ab'), ('03', 'aa'), ('12', 'aa'), ('13', 'ab')], [('02', 'ab'), ('03', 'aa'), ('12', 'aa'), ('13', 'ba')], [('02', 'ab'), ('03', 'aa'), ('12', 'aa'), ('13', 'bb')], [('02', 'ab'), ('03', 'aa'), ('12', 'ab'), ('13', 'aa')], [('02', 'ab'), ('03', 'aa'), ('12', 'ab'), ('13', 'ab')], [('02', 'ab'), ('03', 'aa'), ('12', 'ab'), ('13', 'ba')], [('02', 'ab'), ('03', 'aa'), ('12', 'ab'), ('13', 'bb')], [('02', 'ab'), ('03', 'aa'), ('12', 'ba'), ('13', 'aa')], [('02', 'ab'), ('03', 'aa'), ('12', 'ba'), ('13', 'ab')], [('02', 'ab'), ('03', 'aa'), ('12', 'ba'), ('13', 'ba')], [('02', 'ab'), ('03', 'aa'), ('12', 'ba'), ('13', 'bb')], [('02', 'ab'), ('03', 'aa'), ('12', 'bb'), ('13', 'aa')], [('02', 'ab'), ('03', 'aa'), ('12', 'bb'), ('13', 'ab')], [('02', 'ab'), ('03', 'aa'), ('12', 'bb'), ('13', 'ba')], [('02', 'ab'), ('03', 'aa'), ('12', 'bb'), ('13', 'bb')], [('02', 'ab'), ('03', 'ab'), ('12', 'aa'), ('13', 'aa')], [('02', 'ab'), ('03', 'ab'), ('12', 'aa'), ('13', 'ab')], [('02', 'ab'), ('03', 'ab'), ('12', 'aa'), ('13', 'ba')], [('02', 'ab'), ('03', 'ab'), ('12', 'aa'), ('13', 'bb')], [('02', 'ab'), ('03', 'ab'), ('12', 'ab'), ('13', 'aa')], [('02', 'ab'), ('03', 'ab'), ('12', 'ab'), ('13', 'ab')], [('02', 'ab'), ('03', 'ab'), ('12', 'ab'), ('13', 'ba')], [('02', 'ab'), ('03', 'ab'), ('12', 'ab'), ('13', 'bb')], [('02', 'ab'), ('03', 'ab'), ('12', 'ba'), ('13', 'aa')], [('02', 'ab'), ('03', 'ab'), ('12', 'ba'), ('13', 'ab')], [('02', 'ab'), ('03', 'ab'), ('12', 'ba'), ('13', 'ba')], [('02', 'ab'), ('03', 'ab'), ('12', 'ba'), ('13', 'bb')], [('02', 'ab'), ('03', 'ab'), ('12', 'bb'), ('13', 'aa')], [('02', 'ab'), ('03', 'ab'), ('12', 'bb'), ('13', 'ab')], [('02', 'ab'), ('03', 'ab'), ('12', 'bb'), ('13', 'ba')], [('02', 'ab'), ('03', 'ab'), ('12', 'bb'), ('13', 'bb')], [('02', 'ab'), ('03', 'ba'), ('12', 'aa'), ('13', 'aa')], [('02', 'ab'), ('03', 'ba'), ('12', 'aa'), ('13', 'ab')], [('02', 'ab'), ('03', 'ba'), ('12', 'aa'), ('13', 'ba')], [('02', 'ab'), ('03', 'ba'), ('12', 'aa'), ('13', 'bb')], [('02', 'ab'), ('03', 'ba'), ('12', 'ab'), ('13', 'aa')], [('02', 'ab'), ('03', 'ba'), ('12', 'ab'), ('13', 'ab')], [('02', 'ab'), ('03', 'ba'), ('12', 'ab'), ('13', 'ba')], [('02', 'ab'), ('03', 'ba'), ('12', 'ab'), ('13', 'bb')], [('02', 'ab'), ('03', 'ba'), ('12', 'ba'), ('13', 'aa')], [('02', 'ab'), ('03', 'ba'), ('12', 'ba'), ('13', 'ab')], [('02', 'ab'), ('03', 'ba'), ('12', 'ba'), ('13', 'ba')], [('02', 'ab'), ('03', 'ba'), ('12', 'ba'), ('13', 'bb')], [('02', 'ab'), ('03', 'ba'), ('12', 'bb'), ('13', 'aa')], [('02', 'ab'), ('03', 'ba'), ('12', 'bb'), ('13', 'ab')], [('02', 'ab'), ('03', 'ba'), ('12', 'bb'), ('13', 'ba')], [('02', 'ab'), ('03', 'ba'), ('12', 'bb'), ('13', 'bb')], [('02', 'ab'), ('03', 'bb'), ('12', 'aa'), ('13', 'aa')], [('02', 'ab'), ('03', 'bb'), ('12', 'aa'), ('13', 'ab')], [('02', 'ab'), ('03', 'bb'), ('12', 'aa'), ('13', 'ba')], [('02', 'ab'), ('03', 'bb'), ('12', 'aa'), ('13', 'bb')], [('02', 'ab'), ('03', 'bb'), ('12', 'ab'), ('13', 'aa')], [('02', 'ab'), ('03', 'bb'), ('12', 'ab'), ('13', 'ab')], [('02', 'ab'), ('03', 'bb'), ('12', 'ab'), ('13', 'ba')], [('02', 'ab'), ('03', 'bb'), ('12', 'ab'), ('13', 'bb')], [('02', 'ab'), ('03', 'bb'), ('12', 'ba'), ('13', 'aa')], [('02', 'ab'), ('03', 'bb'), ('12', 'ba'), ('13', 'ab')], [('02', 'ab'), ('03', 'bb'), ('12', 'ba'), ('13', 'ba')], [('02', 'ab'), ('03', 'bb'), ('12', 'ba'), ('13', 'bb')], [('02', 'ab'), ('03', 'bb'), ('12', 'bb'), ('13', 'aa')], [('02', 'ab'), ('03', 'bb'), ('12', 'bb'), ('13', 'ab')], [('02', 'ab'), ('03', 'bb'), ('12', 'bb'), ('13', 'ba')], [('02', 'ab'), ('03', 'bb'), ('12', 'bb'), ('13', 'bb')], [('02', 'ba'), ('03', 'aa'), ('12', 'aa'), ('13', 'aa')], [('02', 'ba'), ('03', 'aa'), ('12', 'aa'), ('13', 'ab')], [('02', 'ba'), ('03', 'aa'), ('12', 'aa'), ('13', 'ba')], [('02', 'ba'), ('03', 'aa'), ('12', 'aa'), ('13', 'bb')], [('02', 'ba'), ('03', 'aa'), ('12', 'ab'), ('13', 'aa')], [('02', 'ba'), ('03', 'aa'), ('12', 'ab'), ('13', 'ab')], [('02', 'ba'), ('03', 'aa'), ('12', 'ab'), ('13', 'ba')], [('02', 'ba'), ('03', 'aa'), ('12', 'ab'), ('13', 'bb')], [('02', 'ba'), ('03', 'aa'), ('12', 'ba'), ('13', 'aa')], [('02', 'ba'), ('03', 'aa'), ('12', 'ba'), ('13', 'ab')], [('02', 'ba'), ('03', 'aa'), ('12', 'ba'), ('13', 'ba')], [('02', 'ba'), ('03', 'aa'), ('12', 'ba'), ('13', 'bb')], [('02', 'ba'), ('03', 'aa'), ('12', 'bb'), ('13', 'aa')], [('02', 'ba'), ('03', 'aa'), ('12', 'bb'), ('13', 'ab')], [('02', 'ba'), ('03', 'aa'), ('12', 'bb'), ('13', 'ba')], [('02', 'ba'), ('03', 'aa'), ('12', 'bb'), ('13', 'bb')], [('02', 'ba'), ('03', 'ab'), ('12', 'aa'), ('13', 'aa')], [('02', 'ba'), ('03', 'ab'), ('12', 'aa'), ('13', 'ab')], [('02', 'ba'), ('03', 'ab'), ('12', 'aa'), ('13', 'ba')], [('02', 'ba'), ('03', 'ab'), ('12', 'aa'), ('13', 'bb')], [('02', 'ba'), ('03', 'ab'), ('12', 'ab'), ('13', 'aa')], [('02', 'ba'), ('03', 'ab'), ('12', 'ab'), ('13', 'ab')], [('02', 'ba'), ('03', 'ab'), ('12', 'ab'), ('13', 'ba')], [('02', 'ba'), ('03', 'ab'), ('12', 'ab'), ('13', 'bb')], [('02', 'ba'), ('03', 'ab'), ('12', 'ba'), ('13', 'aa')], [('02', 'ba'), ('03', 'ab'), ('12', 'ba'), ('13', 'ab')], [('02', 'ba'), ('03', 'ab'), ('12', 'ba'), ('13', 'ba')], [('02', 'ba'), ('03', 'ab'), ('12', 'ba'), ('13', 'bb')], [('02', 'ba'), ('03', 'ab'), ('12', 'bb'), ('13', 'aa')], [('02', 'ba'), ('03', 'ab'), ('12', 'bb'), ('13', 'ab')], [('02', 'ba'), ('03', 'ab'), ('12', 'bb'), ('13', 'ba')], [('02', 'ba'), ('03', 'ab'), ('12', 'bb'), ('13', 'bb')], [('02', 'ba'), ('03', 'ba'), ('12', 'aa'), ('13', 'aa')], [('02', 'ba'), ('03', 'ba'), ('12', 'aa'), ('13', 'ab')], [('02', 'ba'), ('03', 'ba'), ('12', 'aa'), ('13', 'ba')], [('02', 'ba'), ('03', 'ba'), ('12', 'aa'), ('13', 'bb')], [('02', 'ba'), ('03', 'ba'), ('12', 'ab'), ('13', 'aa')], [('02', 'ba'), ('03', 'ba'), ('12', 'ab'), ('13', 'ab')], [('02', 'ba'), ('03', 'ba'), ('12', 'ab'), ('13', 'ba')], [('02', 'ba'), ('03', 'ba'), ('12', 'ab'), ('13', 'bb')], [('02', 'ba'), ('03', 'ba'), ('12', 'ba'), ('13', 'aa')], [('02', 'ba'), ('03', 'ba'), ('12', 'ba'), ('13', 'ab')], [('02', 'ba'), ('03', 'ba'), ('12', 'ba'), ('13', 'ba')], [('02', 'ba'), ('03', 'ba'), ('12', 'ba'), ('13', 'bb')], [('02', 'ba'), ('03', 'ba'), ('12', 'bb'), ('13', 'aa')], [('02', 'ba'), ('03', 'ba'), ('12', 'bb'), ('13', 'ab')], [('02', 'ba'), ('03', 'ba'), ('12', 'bb'), ('13', 'ba')], [('02', 'ba'), ('03', 'ba'), ('12', 'bb'), ('13', 'bb')], [('02', 'ba'), ('03', 'bb'), ('12', 'aa'), ('13', 'aa')], [('02', 'ba'), ('03', 'bb'), ('12', 'aa'), ('13', 'ab')], [('02', 'ba'), ('03', 'bb'), ('12', 'aa'), ('13', 'ba')], [('02', 'ba'), ('03', 'bb'), ('12', 'aa'), ('13', 'bb')], [('02', 'ba'), ('03', 'bb'), ('12', 'ab'), ('13', 'aa')], [('02', 'ba'), ('03', 'bb'), ('12', 'ab'), ('13', 'ab')], [('02', 'ba'), ('03', 'bb'), ('12', 'ab'), ('13', 'ba')], [('02', 'ba'), ('03', 'bb'), ('12', 'ab'), ('13', 'bb')], [('02', 'ba'), ('03', 'bb'), ('12', 'ba'), ('13', 'aa')], [('02', 'ba'), ('03', 'bb'), ('12', 'ba'), ('13', 'ab')], [('02', 'ba'), ('03', 'bb'), ('12', 'ba'), ('13', 'ba')], [('02', 'ba'), ('03', 'bb'), ('12', 'ba'), ('13', 'bb')], [('02', 'ba'), ('03', 'bb'), ('12', 'bb'), ('13', 'aa')], [('02', 'ba'), ('03', 'bb'), ('12', 'bb'), ('13', 'ab')], [('02', 'ba'), ('03', 'bb'), ('12', 'bb'), ('13', 'ba')], [('02', 'ba'), ('03', 'bb'), ('12', 'bb'), ('13', 'bb')], [('02', 'bb'), ('03', 'aa'), ('12', 'aa'), ('13', 'aa')], [('02', 'bb'), ('03', 'aa'), ('12', 'aa'), ('13', 'ab')], [('02', 'bb'), ('03', 'aa'), ('12', 'aa'), ('13', 'ba')], [('02', 'bb'), ('03', 'aa'), ('12', 'aa'), ('13', 'bb')], [('02', 'bb'), ('03', 'aa'), ('12', 'ab'), ('13', 'aa')], [('02', 'bb'), ('03', 'aa'), ('12', 'ab'), ('13', 'ab')], [('02', 'bb'), ('03', 'aa'), ('12', 'ab'), ('13', 'ba')], [('02', 'bb'), ('03', 'aa'), ('12', 'ab'), ('13', 'bb')], [('02', 'bb'), ('03', 'aa'), ('12', 'ba'), ('13', 'aa')], [('02', 'bb'), ('03', 'aa'), ('12', 'ba'), ('13', 'ab')], [('02', 'bb'), ('03', 'aa'), ('12', 'ba'), ('13', 'ba')], [('02', 'bb'), ('03', 'aa'), ('12', 'ba'), ('13', 'bb')], [('02', 'bb'), ('03', 'aa'), ('12', 'bb'), ('13', 'aa')], [('02', 'bb'), ('03', 'aa'), ('12', 'bb'), ('13', 'ab')], [('02', 'bb'), ('03', 'aa'), ('12', 'bb'), ('13', 'ba')], [('02', 'bb'), ('03', 'aa'), ('12', 'bb'), ('13', 'bb')], [('02', 'bb'), ('03', 'ab'), ('12', 'aa'), ('13', 'aa')], [('02', 'bb'), ('03', 'ab'), ('12', 'aa'), ('13', 'ab')], [('02', 'bb'), ('03', 'ab'), ('12', 'aa'), ('13', 'ba')], [('02', 'bb'), ('03', 'ab'), ('12', 'aa'), ('13', 'bb')], [('02', 'bb'), ('03', 'ab'), ('12', 'ab'), ('13', 'aa')], [('02', 'bb'), ('03', 'ab'), ('12', 'ab'), ('13', 'ab')], [('02', 'bb'), ('03', 'ab'), ('12', 'ab'), ('13', 'ba')], [('02', 'bb'), ('03', 'ab'), ('12', 'ab'), ('13', 'bb')], [('02', 'bb'), ('03', 'ab'), ('12', 'ba'), ('13', 'aa')], [('02', 'bb'), ('03', 'ab'), ('12', 'ba'), ('13', 'ab')], [('02', 'bb'), ('03', 'ab'), ('12', 'ba'), ('13', 'ba')], [('02', 'bb'), ('03', 'ab'), ('12', 'ba'), ('13', 'bb')], [('02', 'bb'), ('03', 'ab'), ('12', 'bb'), ('13', 'aa')], [('02', 'bb'), ('03', 'ab'), ('12', 'bb'), ('13', 'ab')], [('02', 'bb'), ('03', 'ab'), ('12', 'bb'), ('13', 'ba')], [('02', 'bb'), ('03', 'ab'), ('12', 'bb'), ('13', 'bb')], [('02', 'bb'), ('03', 'ba'), ('12', 'aa'), ('13', 'aa')], [('02', 'bb'), ('03', 'ba'), ('12', 'aa'), ('13', 'ab')], [('02', 'bb'), ('03', 'ba'), ('12', 'aa'), ('13', 'ba')], [('02', 'bb'), ('03', 'ba'), ('12', 'aa'), ('13', 'bb')], [('02', 'bb'), ('03', 'ba'), ('12', 'ab'), ('13', 'aa')], [('02', 'bb'), ('03', 'ba'), ('12', 'ab'), ('13', 'ab')], [('02', 'bb'), ('03', 'ba'), ('12', 'ab'), ('13', 'ba')], [('02', 'bb'), ('03', 'ba'), ('12', 'ab'), ('13', 'bb')], [('02', 'bb'), ('03', 'ba'), ('12', 'ba'), ('13', 'aa')], [('02', 'bb'), ('03', 'ba'), ('12', 'ba'), ('13', 'ab')], [('02', 'bb'), ('03', 'ba'), ('12', 'ba'), ('13', 'ba')], [('02', 'bb'), ('03', 'ba'), ('12', 'ba'), ('13', 'bb')], [('02', 'bb'), ('03', 'ba'), ('12', 'bb'), ('13', 'aa')], [('02', 'bb'), ('03', 'ba'), ('12', 'bb'), ('13', 'ab')], [('02', 'bb'), ('03', 'ba'), ('12', 'bb'), ('13', 'ba')], [('02', 'bb'), ('03', 'ba'), ('12', 'bb'), ('13', 'bb')], [('02', 'bb'), ('03', 'bb'), ('12', 'aa'), ('13', 'aa')], [('02', 'bb'), ('03', 'bb'), ('12', 'aa'), ('13', 'ab')], [('02', 'bb'), ('03', 'bb'), ('12', 'aa'), ('13', 'ba')], [('02', 'bb'), ('03', 'bb'), ('12', 'aa'), ('13', 'bb')], [('02', 'bb'), ('03', 'bb'), ('12', 'ab'), ('13', 'aa')], [('02', 'bb'), ('03', 'bb'), ('12', 'ab'), ('13', 'ab')], [('02', 'bb'), ('03', 'bb'), ('12', 'ab'), ('13', 'ba')], [('02', 'bb'), ('03', 'bb'), ('12', 'ab'), ('13', 'bb')], [('02', 'bb'), ('03', 'bb'), ('12', 'ba'), ('13', 'aa')], [('02', 'bb'), ('03', 'bb'), ('12', 'ba'), ('13', 'ab')], [('02', 'bb'), ('03', 'bb'), ('12', 'ba'), ('13', 'ba')], [('02', 'bb'), ('03', 'bb'), ('12', 'ba'), ('13', 'bb')], [('02', 'bb'), ('03', 'bb'), ('12', 'bb'), ('13', 'aa')], [('02', 'bb'), ('03', 'bb'), ('12', 'bb'), ('13', 'ab')], [('02', 'bb'), ('03', 'bb'), ('12', 'bb'), ('13', 'ba')], [('02', 'bb'), ('03', 'bb'), ('12', 'bb'), ('13', 'bb')]]\n",
        "log_priors = [-0.9178860550328204, -10.749415928290118, -10.749415928290118, -11.272664072079987, -10.749415928290118, -10.749415928290118, -16.95425710594061, -17.294055179550075, -10.749415928290118, -16.95425710594061, -10.749415928290118, -17.294055179550075, -11.272664072079987, -17.294055179550075, -17.294055179550075, -11.272664072079987, -10.749415928290118, -10.749415928290118, -16.95425710594061, -17.294055179550075, -10.749415928290118, -10.749415928290118, -16.95425710594061, -17.294055179550075, -16.95425710594061, -16.95425710594061, -16.95425710594061, -12.460704095246543, -17.294055179550075, -17.294055179550075, -20.83821243446749, -17.294055179550075, -10.749415928290118, -16.95425710594061, -10.749415928290118, -17.294055179550075, -16.95425710594061, -16.95425710594061, -16.95425710594061, -12.460704095246543, -10.749415928290118, -16.95425710594061, -10.749415928290118, -17.294055179550075, -17.294055179550075, -20.83821243446749, -17.294055179550075, -17.294055179550075, -11.272664072079987, -17.294055179550075, -17.294055179550075, -11.272664072079987, -17.294055179550075, -17.294055179550075, -20.83821243446749, -17.294055179550075, -17.294055179550075, -20.83821243446749, -17.294055179550075, -17.294055179550075, -11.272664072079987, -17.294055179550075, -17.294055179550075, -11.272664072079987, -10.749415928290118, -10.749415928290118, -16.95425710594061, -17.294055179550075, -10.749415928290118, -10.749415928290118, -16.95425710594061, -17.294055179550075, -16.95425710594061, -16.95425710594061, -16.95425710594061, -20.83821243446749, -17.294055179550075, -17.294055179550075, -12.460704095246543, -17.294055179550075, -10.749415928290118, -10.749415928290118, -16.95425710594061, -17.294055179550075, -10.749415928290118, -2.304180416152711, -11.272664072079987, -10.749415928290118, -16.95425710594061, -11.272664072079987, -11.272664072079987, -16.95425710594061, -17.294055179550075, -10.749415928290118, -16.95425710594061, -10.749415928290118, -16.95425710594061, -16.95425710594061, -16.95425710594061, -20.83821243446749, -16.95425710594061, -11.272664072079987, -11.272664072079987, -16.95425710594061, -16.95425710594061, -11.272664072079987, -11.272664072079987, -16.95425710594061, -20.83821243446749, -16.95425710594061, -16.95425710594061, -16.95425710594061, -17.294055179550075, -17.294055179550075, -12.460704095246543, -17.294055179550075, -17.294055179550075, -10.749415928290118, -16.95425710594061, -10.749415928290118, -20.83821243446749, -16.95425710594061, -16.95425710594061, -16.95425710594061, -17.294055179550075, -10.749415928290118, -16.95425710594061, -10.749415928290118, -10.749415928290118, -16.95425710594061, -10.749415928290118, -17.294055179550075, -16.95425710594061, -16.95425710594061, -16.95425710594061, -20.83821243446749, -10.749415928290118, -16.95425710594061, -10.749415928290118, -17.294055179550075, -17.294055179550075, -12.460704095246543, -17.294055179550075, -17.294055179550075, -16.95425710594061, -16.95425710594061, -16.95425710594061, -20.83821243446749, -16.95425710594061, -11.272664072079987, -11.272664072079987, -16.95425710594061, -16.95425710594061, -11.272664072079987, -11.272664072079987, -16.95425710594061, -20.83821243446749, -16.95425710594061, -16.95425710594061, -16.95425710594061, -10.749415928290118, -16.95425710594061, -10.749415928290118, -17.294055179550075, -16.95425710594061, -11.272664072079987, -11.272664072079987, -16.95425710594061, -10.749415928290118, -11.272664072079987, -2.304180416152711, -10.749415928290118, -17.294055179550075, -16.95425710594061, -10.749415928290118, -10.749415928290118, -17.294055179550075, -12.460704095246543, -17.294055179550075, -17.294055179550075, -20.83821243446749, -16.95425710594061, -16.95425710594061, -16.95425710594061, -17.294055179550075, -16.95425710594061, -10.749415928290118, -10.749415928290118, -17.294055179550075, -16.95425710594061, -10.749415928290118, -10.749415928290118, -11.272664072079987, -17.294055179550075, -17.294055179550075, -11.272664072079987, -17.294055179550075, -17.294055179550075, -20.83821243446749, -17.294055179550075, -17.294055179550075, -20.83821243446749, -17.294055179550075, -17.294055179550075, -11.272664072079987, -17.294055179550075, -17.294055179550075, -11.272664072079987, -17.294055179550075, -17.294055179550075, -20.83821243446749, -17.294055179550075, -17.294055179550075, -10.749415928290118, -16.95425710594061, -10.749415928290118, -12.460704095246543, -16.95425710594061, -16.95425710594061, -16.95425710594061, -17.294055179550075, -10.749415928290118, -16.95425710594061, -10.749415928290118, -17.294055179550075, -20.83821243446749, -17.294055179550075, -17.294055179550075, -12.460704095246543, -16.95425710594061, -16.95425710594061, -16.95425710594061, -17.294055179550075, -16.95425710594061, -10.749415928290118, -10.749415928290118, -17.294055179550075, -16.95425710594061, -10.749415928290118, -10.749415928290118, -11.272664072079987, -17.294055179550075, -17.294055179550075, -11.272664072079987, -17.294055179550075, -10.749415928290118, -16.95425710594061, -10.749415928290118, -17.294055179550075, -16.95425710594061, -10.749415928290118, -10.749415928290118, -11.272664072079987, -10.749415928290118, -10.749415928290118, -0.9178860550328204]\n",
        "language_types = [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9tYOjI1xl5f"
      },
      "source": [
        "Measure the length of `possible_languages` by typing in `len(possible_languages)` to check whether you correctly figured out how many possible languages there should be. Using the `language_types` list, can you find the first holistic language in the list? Does it make sense that this language is classed as holistic? How does its prior probability compare to the first degenerate language in the list?\n",
        "\n",
        "If you want to see all the languages laid out along with their type and prior, you can do something like this:\n",
        "```python\n",
        "for i in range(len(possible_languages)):\n",
        "    print(possible_languages[i], language_types[i], log_priors[i])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSGPeEwRxl5f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpRR8AUxxl5f"
      },
      "source": [
        "## The rest of the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1Yx1zrKxl5f"
      },
      "source": [
        "Now we have our representation of languages we can get on with the rest of the code. First we'll import our various libraries and define some functions we need for working with log probabilities. You don't need to worry too much about how all this works to play with these simulations, but you can ask me about them in class!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75eGCUckxl5f"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from math import log, log1p, exp\n",
        "from scipy.special import logsumexp\n",
        "\n",
        "def normalize_logprobs(logprobs):\n",
        "    \"\"\"Takes a list of log numbers; returns a list of scaled versions of those numbers that,\n",
        "    once converted to probabilities, sum to 1.\"\"\"\n",
        "    logtotal = logsumexp(logprobs) #calculates the summed log probabilities\n",
        "    normedlogs = []\n",
        "    for logp in logprobs:\n",
        "        normedlogs.append(logp - logtotal) #normalise - subtracting in the log domain equivalent to divising in the normal domain\n",
        "    return normedlogs\n",
        "\n",
        "def log_roulette_wheel(normedlogs):\n",
        "    \"\"\"Takes a list of normed log probabilities; returns some index of that list\n",
        "    with probability corresponding to the (exponentiated) value of that list element\"\"\"\n",
        "    r=log(random.random()) #generate a random number in [0,1), then convert to log\n",
        "    accumulator = normedlogs[0]\n",
        "    for i in range(len(normedlogs)):\n",
        "        if r < accumulator:\n",
        "            return i\n",
        "        accumulator = logsumexp([accumulator, normedlogs[i + 1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYWNQKVSxl5g"
      },
      "source": [
        "## The learner\n",
        "\n",
        "The `update_posterior` function does all the work really. For this simulation we need a way of gradually learning as we go along, because when the agents are interacting, they need to use what they've learned so far to speak, but also continue to learn. What we're doing here is taking whatever the prior probability is for each language and multiplying that with the likelihood of the data that they just heard. This gives us the posterior probability of the language given the meaning-signal pair that the learner just heard.\n",
        "\n",
        "So, what do we do when the learner hears the next bit of data? We can just treat the posterior we calculated as if it's the new prior. In this way, the posterior probability of the languages can gradually be \"updated\" as the agents hear data.\n",
        "\n",
        "So, this function takes as input the current posterior, and a meaning and signal. It then works out for each language what the probability of that language generating that meaning-signal pair would be. This will be $1-\\epsilon$ (where $\\epsilon$ is the probability that a speaker could have made a mistake and said something wrong, e.g. 0.05) if that meaning-signal pair is in the language and $\\epsilon/3$ if that meaning-signal pair is not in the language. This is because the errors that the speaker might make are shared across all the signals, meaning that the probability of the correct data is slightly less than 1, and the probability of the wrong data is slightly greater than 0.\n",
        "\n",
        "Because these are log probabilities, the new posterior probability for each language is just the posterior probability for that language before, plus the likelihood (normalised so everything adds up to one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXfsvQ5Bxl5g"
      },
      "outputs": [],
      "source": [
        "def update_posterior(posterior, meaning, signal, signals, possible_languages, error_probability):\n",
        "    \"\"\"\n",
        "    Takes posterior (list of 256 log probabilities, one for each language), meaning (two-digit numeric string,\n",
        "    e.g., '02'), signal (two-letter string, e.g., 'aa', the list of possible signals, the list possible languages,\n",
        "    and the error probability.\n",
        "    Returns normalised log probability distribution over languages.\n",
        "    \"\"\"\n",
        "    in_language = log(1 - error_probability)\n",
        "    out_of_language = log(error_probability / (len(signals) - 1))\n",
        "    new_posterior = []\n",
        "    for i in range(len(posterior)):\n",
        "        if (meaning, signal) in possible_languages[i]:\n",
        "            new_posterior.append(posterior[i] + in_language)\n",
        "        else:\n",
        "            new_posterior.append(posterior[i] + out_of_language)\n",
        "    return normalize_logprobs(new_posterior)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyaboLDFxl5g"
      },
      "source": [
        "Let's check that the `update_posterior` function makes sense. Try the following:\n",
        "\n",
        "```python\n",
        "print(log_priors[0])\n",
        "new_log_posterior = update_posterior(log_priors, '02', 'aa', signals, possible_languages, 0.05)\n",
        "print(new_log_posterior[0])\n",
        "```\n",
        "\n",
        "This essentially imagines a \"newborn\" agent, whose current posterior is the same as the prior (since the prior is just what you believe before seeing any data). That newborn hears the signal `aa` paired with the meaning `02` and updates their posterior as a result. What is printed is the posterior probability before and after this experience for the first language in the list, which you can see by typing:\n",
        "\n",
        "```python\n",
        "possible_languages[0]\n",
        "```\n",
        "\n",
        "*Try a few other meaning-signal pairs and look at other parts of the posterior list. What would you type in to have the posterior update for a second time, as if the newborn had heard a second meaning-signal pair?*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iShFg0j0xl5h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGX8SGD6xl5h"
      },
      "source": [
        "Finally, we have a function to return a specific language from the posterior by sampling a language at random but weighted according to the posterior probability of each language. This function is called a \"roulette wheel\" by analogy to a weird roulette wheel in a casino where some of the slots a wider than others. The width of the slots here is the posterior probability. Probable languages have wide slots, improbable slots have narrow ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDBLy_Evxl5h"
      },
      "outputs": [],
      "source": [
        "def sample(posterior):\n",
        "    \"\"\"\n",
        "    Takes posterior (list of log probabilities for every language).\n",
        "    Returns one language (list of four 2-tuples) sampled proportional to its posterior probability.\n",
        "    \"\"\"\n",
        "    selected_index = log_roulette_wheel(posterior)\n",
        "    return possible_languages[selected_index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2bSgpSXxl5h"
      },
      "source": [
        "## Production, reception, and iterated learning\n",
        "\n",
        "The next chunk of code handles the actual iterated learning simulation.\n",
        "\n",
        "First, we have a function for a literal listener, `literal_listener`, which takes a signal and a language and returns a meaning. The literal listener is so called because it doesn't do any pragmatic inference - it just takes the signal on face value and figures out what it means according to its beliefs about the language being used. If there are multiple possible meanings, it chooses one at random."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fywoqhZxl5h"
      },
      "outputs": [],
      "source": [
        "def literal_listener(language, signal, meanings):\n",
        "    \"\"\"\n",
        "    Takes language (list of four 2-tuples), signal (two-character string, e.g., 'aa'), and all possible meanings.\n",
        "    Returns a meaning that the literal listener associates with this signal.\n",
        "    \"\"\"\n",
        "    possibles = []\n",
        "    for m, s in language:\n",
        "        if s == signal:\n",
        "            possibles.append(m) # Possibles ends up with all the meanings that are mapped to the signal\n",
        "    if possibles == []:\n",
        "        return random.choice(meanings) # If we don't have any meanings for the signal, just guess!\n",
        "    else:\n",
        "        return random.choice(possibles) # Otherwise, pick one of the possible meanings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBXzGb6hxl5i"
      },
      "source": [
        "The literal speaker function `literal_speaker` takes a language and a meaning and returns the signal for that meaning in that language (assuming it doesn't turn out to be one of the times the speaker is making a mistake).\n",
        "\n",
        "The pragmatic speaker function `pragmatic_speaker` does a highly simplified version of the Rational Speech Act (RSA) model discussed in the paper. It first considers what a literal speaker would say, then checks what a literal listener would think that signal means. If that meaning is the wrong one (for example, this could happen if the signal was ambiguous in the language) it chooses another signal at random. This isn't quite as powerful as the full RSA model but works surprisingly well.\n",
        "\n",
        "(N.B. The learner doesn't take this fact into account when calculating the likelihood as part of our `update_posterior` function above. It's like the learner doesn't know that the speaker is trying to be helpful. This turns out to be quite important for reasons you might enjoy thinking about...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0wlP-4Wxl5i"
      },
      "outputs": [],
      "source": [
        "def literal_speaker(language, meaning, signals, error_probability):\n",
        "    \"\"\"\n",
        "    Takes language (list of four 2-tuples), meaning (two-digit string, e.g., '02'), all possible signals,\n",
        "    and error probability.\n",
        "    Returns a signal that the speaker produces for this meaning.\n",
        "    \"\"\"\n",
        "    for m, s in language:\n",
        "        if m == meaning:\n",
        "            signal = s # find the signal that is mapped to the meaning\n",
        "                       # (nb. there's no synonymy possible in this model!)\n",
        "\n",
        "    if random.random() < error_probability: # add the occasional mistake\n",
        "        other_signals = []\n",
        "        for other_signal in signals:\n",
        "            if other_signal != signal:\n",
        "                other_signals.append(other_signal) # make a list of all the \"wrong\" signals\n",
        "        return random.choice(other_signals) # pick one of them\n",
        "\n",
        "    return signal\n",
        "\n",
        "\n",
        "def pragmatic_speaker(language, meaning, meanings, signals, error_probability):\n",
        "    \"\"\"\n",
        "    Takes language (list of four 2-tuples), meaning (two-digit string, e.g., '02'), all possible meanings,\n",
        "    all possible signals, and error probability.\n",
        "    Returns a signal that the pragmatic speaker produces for this meaning.\n",
        "    \"\"\"\n",
        "    signal = literal_speaker(language, meaning, signals, error_probability)\n",
        "    listener_meaning = literal_listener(language, signal, signals) # check what a listener would think that signal would mean\n",
        "    if listener_meaning != meaning:\n",
        "        signal = random.choice(signals) # if the intended meaning is different from the received one,\n",
        "                                        # pick a different signal at random\n",
        "    return signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxFyIXEcxl5j"
      },
      "source": [
        "*Try the receive and produce functions out to make sure they make sense, e.g. by typing: `literal_speaker(possible_languages[0], '02', signals, 0.05)` several times (or better still running it many times in a loop).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnkUjronxl5j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hG30zLdxl5j"
      },
      "source": [
        "The next two functions handle the population. `new_population` creates a population of newborn agents, each with their posterior over grammars equal to the prior.\n",
        "\n",
        "`population_communication` has pairs of agents in the population communicate with each other for a certain number of rounds. As they communicate, the hearer learns (i.e. updates the posterior) from the meaning-signal pairs the speaker produces. The function returns the data (i.e. meaning-signal pairs) that was produced by all the interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqieaEf6xl5j"
      },
      "outputs": [],
      "source": [
        "def new_population(popsize, log_priors):\n",
        "    \"\"\"\n",
        "    Takes popsize (number) and the log_prior distribution; returns list of log prior probability distributions,\n",
        "    one per agent in the population.\n",
        "    \"\"\"\n",
        "    population = []\n",
        "    for i in range(popsize):\n",
        "        baby = []\n",
        "        for p in log_priors:\n",
        "            baby.append(p)\n",
        "        population.append(baby) # each newborn starts out with only the prior distribution\n",
        "    return population\n",
        "\n",
        "def population_communication(population, rounds, meanings, signals,\n",
        "                             possible_languages, pragmatic, error_probability):\n",
        "    \"\"\"\n",
        "    Takes population (list of lists, log prior probability distributions) and rounds (number), possible meanings,\n",
        "    possible signals, possible languages, a boolean for whether to use a pragmatic speaker or not, and error\n",
        "    probability.\n",
        "    Returns list of tuples of form (meaning, signal), one tuple per round.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for i in range(rounds):\n",
        "        meaning = random.choice(meanings) # pick a meaning\n",
        "\n",
        "        speaker_index = random.randrange(len(population)) # pick a speaker\n",
        "        speaker_posterior = population[speaker_index]\n",
        "        listener_index = random.randrange(len(population) - 1) # pick a listener\n",
        "        if listener_index >= speaker_index: # make sure the speaker and listener are different\n",
        "            listener_index += 1\n",
        "        listener_posterior = population[listener_index]\n",
        "\n",
        "        language = sample(speaker_posterior) # sample a language from the speakers posterior\n",
        "\n",
        "        if pragmatic:\n",
        "            signal = pragmatic_speaker(language, meaning, meanings, signals, error_probability) # pragmatic signal\n",
        "        else:\n",
        "            signal = literal_speaker(language, meaning, meanings, error_probability) # literal signal\n",
        "\n",
        "        population[listener_index] = update_posterior(listener_posterior, meaning, signal,\n",
        "                                                      signals, possible_languages,\n",
        "                                                      error_probability) # update the listener\n",
        "\n",
        "        data.append((meaning, signal)) # add the meaning, signal pair to the data that the function returns\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYB1uvhYxl5j"
      },
      "source": [
        "Now, we have the actual simulation function, and a wee supporting function that gives some summary statistics about the overall posterior probability for *degenerate*, *holistic*, *other*, and *compositional* languages. This is purely to make visualising the results easier!\n",
        "\n",
        "The `simulation` function takes as input a number of generations to run the simulation, the number of rounds of interaction there will be each generation, the \"bottleneck\" on cultural transmission (i.e. the number of meaning-signal pairs passed on to the next generation), the population size, and the language that the very first generation is going to learn from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yD0jFfhJxl5j"
      },
      "outputs": [],
      "source": [
        "def language_stats(posteriors):\n",
        "    \"\"\"Takes posteriors (list of lists (one per agent, each list is that agent's log probability distribution));\n",
        "    returns list with average posterior probability of each language type in the population of agents\"\"\"\n",
        "    stats = [0., 0., 0., 0.] # degenerate, holistic, other, compositional\n",
        "    # Look at each agent's posterior distribution one by one.\n",
        "    for p in posteriors:\n",
        "\n",
        "        # Look at each language's probability in that distribution.\n",
        "        for i in range(len(p)):\n",
        "\n",
        "            # Divide the probability by the number of agents and add to correct entry in stats list.\n",
        "            stats[language_types[i]] += exp(p[i]) / len(posteriors) # the stats will be the average posterior probability\n",
        "                                                                    # in the population. Note the conversion from log back\n",
        "                                                                    # to normal probabilities\n",
        "    return stats\n",
        "\n",
        "\n",
        "def simulation(generations, rounds, bottleneck, popsize, language, log_priors,\n",
        "               meanings, signals, possible_languages, pragmatic, turnover, error_probability):\n",
        "    \"\"\"\n",
        "    Takes:\n",
        "        generations: the number of generations to simulate.\n",
        "        rounds: the number of communication rounds per generation.\n",
        "        bottleneck: the number of learning trials per speaker per generation.\n",
        "        popsize: the number of agents in each generation.\n",
        "        language: list of four 2-tuples of form (meaning, signal).\n",
        "        log_priors: the log prior probability distribution.\n",
        "        meanings: a list of all possible meanings.\n",
        "        signals: a list of all possible signals.\n",
        "        possible_languages: a list of all possible languages.\n",
        "        pragmatic: a boolean to say whether to use pragmatic speakers or not.\n",
        "        turnover: a boolean to say whether to use population turnover or not.\n",
        "        error_probability: the error probability.\n",
        "    Returns:\n",
        "        List of lists, one per generation; each list is the\n",
        "        average posterior probabilities of each language type.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    population = new_population(popsize, log_priors)\n",
        "    data = language # the data that the first generation is trained on is just whatever language we input\n",
        "\n",
        "    for i in range(generations):\n",
        "        for j in range(popsize): # First off, every learner gets a chance to learn\n",
        "\n",
        "            for k in range(bottleneck): # Do a bunch of learning trials\n",
        "                meaning, signal = random.choice(data) # choose a meaning, signal pair at random from the previous\n",
        "                                                      # generation's data\n",
        "                population[j] = update_posterior(population[j], meaning, signal,\n",
        "                                                 signals, possible_languages,\n",
        "                                                 error_probability) # learn the meaning, signal pair\n",
        "\n",
        "        data = population_communication(population, rounds, meanings, signals,\n",
        "                                        possible_languages, pragmatic,\n",
        "                                        error_probability) # gather data from a bunch of communication rounds\n",
        "        results.append(language_stats(population)) # add stats to the results\n",
        "\n",
        "        if turnover:\n",
        "            population = new_population(popsize, log_priors) # replace the population if the turnover variable is true\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd75GPbLxl5j"
      },
      "source": [
        "## Running the simulation (at last!)\n",
        "\n",
        "We've got a handy function to plot the results of a bunch of simulation runs, which will show us the average posterior probability assigned to *degenerate*, *holistic*, and *compositional* languages on one graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZ67IYTGxl5k"
      },
      "outputs": [],
      "source": [
        "def plot_graph(results):\n",
        "    \"\"\"\n",
        "    Takes results (list of lists, one per generation; each list is the\n",
        "    average posterior probabilities of each language type.\n",
        "    Returns nothing, but plots these probabilities as a function of generations.\n",
        "    \"\"\"\n",
        "\n",
        "    average_degenerate = []\n",
        "    average_holistic = []\n",
        "    average_compositional = []\n",
        "\n",
        "    for i in range(len(results[0])):\n",
        "        total_degenerate = 0\n",
        "        total_holistic = 0\n",
        "        total_compositional = 0\n",
        "        for result in results:\n",
        "            total_degenerate += result[i][0]\n",
        "            total_holistic += result[i][1]\n",
        "            total_compositional += result[i][3]\n",
        "        average_degenerate.append(total_degenerate / len(results))\n",
        "        average_holistic.append(total_holistic / len(results))\n",
        "        average_compositional.append(total_compositional / len(results))\n",
        "\n",
        "    plt.plot(average_degenerate, color='orange', label='degenerate')\n",
        "    plt.plot(average_holistic, color='green', label='holistic')\n",
        "    plt.plot(average_compositional, color='purple', label='compositional')\n",
        "    plt.xlabel('generations')\n",
        "    plt.ylabel('proportion')\n",
        "    plt.legend()\n",
        "    plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmQHgHGlxl5k"
      },
      "source": [
        "Try the following code to create a graph to see whether compositional languages emerge with the model with population turnover but with speakers not being rationally communicative. This will run the simulation 10 times and show you an average, which may take a few minutes to run. You can also try plotting a single run using `plot_graph([simulation(100, 20, 20, 2, initial_language, log_priors, meanings, signals, possible_languages, False, True, 0.05)])`, if you want to see what happens in a single run of the simulation and see why the averaging is important!\n",
        "\n",
        "```python\n",
        "initial_language = [('02', 'aa'), ('03', 'ab'), ('12', 'bb'), ('13', 'ba')]\n",
        "pragmatic = False\n",
        "turnover = True\n",
        "results = []\n",
        "for i in range(10):\n",
        "    results.append(simulation(100, 20, 20, 2, initial_language, log_priors,\n",
        "                              meanings, signals, possible_languages,\n",
        "                              pragmatic, turnover, 0.05))\n",
        "plot_graph(results)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsvE3mICxl5k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86MO43f3xl5k"
      },
      "source": [
        "## Questions\n",
        "\n",
        "1. Try different values for the `pragmatic` and `turnover` parameters. Can you replicate the main results from the [Kirby et al (2015)](https://www.sciencedirect.com/science/article/pii/S0010027715000815?via%3Dihub) paper?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z08YEVOZxl5k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI7h2fodxl5k"
      },
      "source": [
        "2. With both pragmatic speakers and population turnover, what effect does changing the bottleneck size have, and why? (We refer to the \"bottleneck\" in iterated learning to refer to the amount of data that each generation gets to reconstruct the language of the previous generation - the metaphor is one of a narrow bottleneck through which language must squeeze repeatedly over multiple generations.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7ysNhP9xl5k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "096RRjY_xl5k"
      },
      "source": [
        "3. Why do we need a `error_probability` parameter? What happens if the error probability is zero? (Hint: think about how you calculate the likelihood of any of the languages if the data you're learning from actually comes from multiple languages.) What about when it is very close to zero or very close to 1?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kvws771xxl5l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "2254d95886abd510fdbe4740a73329c02480b002321aba449e3a8ac32ef99413"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}